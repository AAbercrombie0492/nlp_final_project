{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from gensim_modeling import *\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autotagging with Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec can learn tag sequences as they cooccur with with document text. Therefore, all of the tags in our dataset have an embeding in the Doc2Vec word embedding space.\n",
    "\n",
    "A naive approach to quantizing a document is to take the average of the word vectors in that document and assign the average to the document.\n",
    "\n",
    "In regards to autotagging, the idea is to quantize a document, search for k-nearest neighbors in the word embedding space, and filter for labeled tags with a cosine similiarity criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "![](images/2_pass_IR_system.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "balanced_classes_file = open(\"pickle_jar/dataframes/classify_Stopwords_3xTitle_ner_stripPunct_dataframe.p\", 'rb')\n",
    "balanced_classes_data = pickle.load(balanced_classes_file)\n",
    "\n",
    "balanced_classes_tag_counter_file = open('pickle_jar/tag_counters/classify_Stopwords_3xTitle_ner_stripPunct_tag_counts.p', 'rb')\n",
    "balanced_classes_tag_counter = pickle.load(balanced_classes_tag_counter_file)\n",
    "\n",
    "balanced_classes_bow_counter_file = open('pickle_jar/post_counters/classify_Stopwords_3xTitle_ner_stripPunct_token_counts.p', 'rb')\n",
    "balanced_classes_bow_counter = pickle.load(balanced_classes_bow_counter_file)\n",
    "\n",
    "\n",
    "thread_dict = {'biology':0,'cooking':1,'crypto':2,'diy':3,'robotics':4,'travel':5}\n",
    "balanced_classes_data['thread_ids'] = balanced_classes_data.thread.apply(lambda x: thread_dict[x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d2v_model = doc2vec.Doc2Vec.load('doc2vec_models/balanced.doc2vec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_predictions = auto_tag(d2v_model, 300, balanced_classes_data, 500, balanced_classes_tag_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_tags = balanced_classes_data['tags'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      "Additional Power to DC Motor via Second Power Source\n",
      "\n",
      "ELABORATION:\n",
      "<p>How can I provide more power to a DC motor that is in series behind a receiver circuit hacked out of a cheap RC car without burning up the receiver board? The board runs off two AAs at about 3V. I'm replacing the stock motor with a slightly larger one (12V, taken from a printer) and remounting it on a chassis for a homebrew robotics project... just messing around to learn more. I imagine I could go safely to 4.5V or even 6V with the receiver but I don't want to go much higher since half the stuff is epoxied and I can't really tell what's in there.</p>\n",
      "\n",
      "<p>What I'd like to be able to do is add an additional two AA batteries behind the receiver to run the receiver system at 6V but add another two 3V 123A batteries to have the motor at 12V with the ability to run with the higher current draw due to the heavier load the motor will handle on its fancy new chassis... but without pulling that current through the receiver circuit.</p>\n",
      "\n",
      "<p>My first thought is to simply connect my 123As negative to the motor and positive to a common ground... but I'm really not sure and I want to be careful to not damage the circuit or batteries. My next thought is to simply build a single power supply out of my 123As and use a current divider but I've only read about them and never actually tried so.</p>\n",
      "\n",
      "<p>I've been doing some of those kiddie \"electronic playgrounds,\" a few books and probably cost Google an extra few bucks in energy costs and I'm still kinda at a loss.</p>\n",
      "\n",
      "\n",
      "TAGS:\n",
      "['b', 'motor', 'power']\n",
      "\n",
      "AUTOTAGS:\n",
      "['and', 'the', 'multi', 'lighting', 'brownies']\n",
      "\n",
      "CLASS: ***robotics***\n"
     ]
    }
   ],
   "source": [
    "def view_example_post(index):\n",
    "    print(\"QUESTION:\\n{}\\n\".format(balanced_classes_data['title'].iloc[index]))\n",
    "\n",
    "    print(\"ELABORATION:\\n{}\\n\".format(balanced_classes_data['content'].iloc[index]))\n",
    "\n",
    "    print(\"TAGS:\\n{}\\n\".format(balanced_classes_data['tags'].iloc[index]))\n",
    "    \n",
    "    print(\"AUTOTAGS:\\n{}\\n\".format(tag_predictions[index]))\n",
    "\n",
    "    print(\"CLASS: ***{}***\".format(balanced_classes_data['thread'].iloc[index]))\n",
    "\n",
    "\n",
    "view_example_post(np.random.randint(0,len(balanced_classes_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_autotag(ytrue,ypred):\n",
    "    tprs = []\n",
    "    fprs = []\n",
    "    for t,p in zip(ytrue, ypred):\n",
    "        row_tps = 0\n",
    "        row_fps = 0\n",
    "        for tkn in t:\n",
    "            if tkn in p:\n",
    "                row_tps += 1\n",
    "            else:\n",
    "                row_fps += 1\n",
    "#         tpr = row_tps/len(ytrue)\n",
    "#         fpr = row_fps/len(ytrue)\n",
    "                \n",
    "        tprs.append(row_tps)\n",
    "        fprs.append(row_fps)\n",
    "    \n",
    "    return tprs, fprs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025844391999071459"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr, fpr = evaluate_autotag(true_tags, tag_predictions)\n",
    "\n",
    "accuracy = sum(tpr)/sum(fpr)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a lot of work to be done to improve my autotagging scheme. Here are some components to approve:\n",
    "\n",
    "- Cosine Similarity threshold for identify tag candidates -- Bayesian Methods\n",
    "\n",
    "- Filtering for labeled tags in Doc2Vec embedding.\n",
    "\n",
    "- Classify document thread, then search for tags in Doc2Vec embedding tailored for a specific domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
